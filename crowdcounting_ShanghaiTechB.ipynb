{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.models import model_from_json\n#from utils_gen import gen_paths_img_dm, gen_var_from_paths\n#from utils_imgproc import norm_by_imagenet\n%matplotlib inline\nplt.ioff()\nimport glob\n\n\n\n\nimport cv2\nimport numpy as np\n\n\ndef smallize_density_map(density_map, stride=1):\n    if stride > 1:\n        density_map_stride = np.zeros((np.asarray(density_map.shape).astype(int)//stride).tolist(), dtype=np.float32)\n        for r in range(density_map_stride.shape[0]):\n            for c in range(density_map_stride.shape[1]):\n                density_map_stride[r, c] = np.sum(density_map[r*stride:(r+1)*stride, c*stride:(c+1)*stride])\n    else:\n        density_map_stride = density_map\n    return density_map_stride\n\n\ndef norm_by_imagenet(img):\n    if len(img.shape) == 3:\n        img = img / 255.0\n        img[:, :, 0] = (img[:, :, 0] - 0.485) / 0.229\n        img[:, :, 1] = (img[:, :, 1] - 0.456) / 0.224\n        img[:, :, 2] = (img[:, :, 2] - 0.406) / 0.225\n        return img\n    elif len(img.shape) == 4 or len(img.shape) == 1:\n        # In SHA, shape of images varies, so the array.shape is (N, ), that's the '== 1' case.\n        imgs = []\n        for im in img:\n            im = im / 255.0\n            im[:, :, 0] = (im[:, :, 0] - 0.485) / 0.229\n            im[:, :, 1] = (im[:, :, 1] - 0.456) / 0.224\n            im[:, :, 2] = (im[:, :, 2] - 0.406) / 0.225\n            imgs.append(im)\n        return np.array(imgs)\n    else:\n        print('Wrong shape of the input.')\n        return None\n\n\n\ndef image_preprocessing(x, y, flip_hor=False, brightness_shift=False):\n    xs, ys = [], []\n    for idx_pro in range(x.shape[0]):\n        x_, y_ = x[idx_pro], y[idx_pro]\n        # preprocessings -----\n        if flip_hor:\n            x_, y_ = flip_horizontally(x_, y_)\n        # preprocessings -----\n        x_ = norm_by_imagenet(x_)\n        #print(x_)\n        #print(x_.shape)\n        #print(y_)\n        #print(y_.shape)\n        xs.append(x_)\n        ys.append(y_)\n    xs, ys = np.array(xs), np.array(ys)\n    return xs, ys\n\n\n\ndef flip_horizontally(x, y):\n    to_flip = np.random.randint(0, 2)\n    if to_flip:\n        x, y = cv2.flip(x, 1), np.expand_dims(cv2.flip(np.squeeze(y), 1), axis=-1)\n        # Suppose shape of y is (123, 456, 1), after cv2.flip, shape of y would turn into (123, 456).\n    return x, y\n\n\ndef fix_singular_shape(img, unit_len=16):\n    \"\"\"\n    Some network like w-net has both N maxpooling layers and concatenate layers,\n    so if no fix for their shape as integeral times of 2 ** N, the shape will go into conflict.\n    \"\"\"\n    #hei_dst, wid_dst = img.shape[0] + (unit_len - img.shape[0] % unit_len), img.shape[1] + (unit_len - img.shape[1] % unit_len)\n    hei_dst,wid_dst=900,900\n    if len(img.shape) == 3:\n        img = cv2.resize(img, (hei_dst, wid_dst), interpolation=cv2.INTER_LANCZOS4)#i changes it to 900 and same down\n    elif len(img.shape) == 2:\n        GT = int(round(np.sum(img)))\n        img = cv2.resize(img, (hei_dst, wid_dst), interpolation=cv2.INTER_LANCZOS4)\n        img = img / (np.sum(img) / GT)\n    return img\n\nimport os\nimport cv2\nimport h5py\nimport scipy\nimport numpy as np\n\nfrom keras.preprocessing.image import ImageDataGenerator\n#from utils_imgproc import smallize_density_map, fix_singular_shape\n\n\ndef gen_paths_img_dm(path_inp):\n    img_paths = []\n    dm_paths=[]\n    ips = os.path.join(path_inp, 'images')\n    dps= os.path.join(path_inp, 'ground-truth-h5')\n    ipaths=[ips]\n    dpaths=[dps]\n\n    for path in ipaths:\n    \n        for img_path in glob.glob(os.path.join(path, '*.jpg')):\n        \n           img_paths.append(str(img_path))\n        \n    print(\"Total images : \",len(img_paths))\n\n    for path in dpaths:\n    \n        for dm_path in glob.glob(os.path.join(path, '*.h5')):\n        \n             dm_paths.append(str(dm_path))\n        \n     #print(\"Total images : \",len(img_paths))\n\n    return img_paths, dm_paths\n\ndef gen_var_from_paths(paths, stride=1, unit_len=16):\n    vars = []\n    unit_len=10\n    format_suffix = paths[0].split('.')[-1]\n    if format_suffix == 'h5':\n        for ph in paths:\n            print(h5py.File(ph, 'r')['density'])\n            dm = h5py.File(ph, 'r')['density'][()].astype(np.float32)\n            print(dm)\n            #if unit_len:\n            dm = fix_singular_shape(dm, unit_len=unit_len)\n            print(dm)\n            dm = smallize_density_map(dm, stride=stride)\n            print(dm)\n            vars.append(np.expand_dims(dm, axis=-1))\n    elif format_suffix == 'jpg':\n        for ph in paths:\n            raw = cv2.cvtColor(cv2.imread(ph), cv2.COLOR_BGR2RGB).astype(np.float32)\n            #if unit_len:\n            raw = fix_singular_shape(raw, unit_len=unit_len)\n            vars.append(raw)\n        # vars = norm_by_imagenet(vars)\n    else:\n        print('Format suffix is wrong.')\n    return np.array(vars)\n\ndef gen_density_map_gaussian(im, points, sigma=4):\n    \"\"\"\n    func: generate the density map\n    \"\"\"\n    density_map = np.zeros(im.shape[:2], dtype=np.float32)\n    h, w = density_map.shape[:2]\n    num_gt = np.squeeze(points).shape[0]\n    if num_gt == 0:\n        return density_map\n    if sigma == 4:\n        # Adaptive sigma in CSRNet.\n        leafsize = 2048\n        tree = scipy.spatial.KDTree(points.copy(), leafsize=leafsize)\n        distances, _ = tree.query(points, k=4)\n    for idx_p, p in enumerate(points):\n        p = np.round(p).astype(int)\n        p[0], p[1] = min(h-1, p[1]), min(w-1, p[0])\n        gaussian_radius = sigma * 2 - 1\n        if sigma == 4:\n            # Adaptive sigma in CSRNet.\n            sigma = max(int(np.sum(distances[idx_p][1:4]) * 0.1), 1)\n            gaussian_radius = sigma * 3\n        gaussian_map = np.multiply(\n            cv2.getGaussianKernel(int(gaussian_radius*2+1), sigma),\n            cv2.getGaussianKernel(int(gaussian_radius*2+1), sigma).T\n        )\n        x_left, x_right, y_up, y_down = 0, gaussian_map.shape[1], 0, gaussian_map.shape[0]\n        # cut the gaussian kernel\n        if p[1] < gaussian_radius:\n            x_left = gaussian_radius - p[1]\n        if p[0] < gaussian_radius:\n            y_up = gaussian_radius - p[0]\n        if p[1] + gaussian_radius >= w:\n            x_right = gaussian_map.shape[1] - (gaussian_radius + p[1] - w) - 1\n        if p[0] + gaussian_radius >= h:\n            y_down = gaussian_map.shape[0] - (gaussian_radius + p[0] - h) - 1\n        gaussian_map = gaussian_map[y_up:y_down, x_left:x_right]\n        if np.sum(gaussian_map):\n            gaussian_map = gaussian_map / np.sum(gaussian_map)\n        density_map[\n            max(0, p[0]-gaussian_radius):min(h, p[0]+gaussian_radius+1),\n            max(0, p[1]-gaussian_radius):min(w, p[1]+gaussian_radius+1)\n        ] += gaussian_map\n    density_map = density_map / (np.sum(density_map / num_gt))\n    return density_map\n\n\nimport os\nimport cv2\nimport h5py\nimport scipy\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n#from utils_imgproc import smallize_density_map, fix_singular_shape\nimport keras.backend as K\n\n\ndef MSE_BCE(y_true, y_pred, alpha=1000, beta=10):\n    mse = K.mean(K.square(y_true - y_pred), axis=-1)\n    bce = K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n    return alpha * mse + beta * bce\n\n    \n\nimport os\nimport cv2\nimport numpy as np\n#from skimage.measure import compare_psnr, compare_ssim\nimport matplotlib.pyplot as plt\n\n\ndef callbacks_during_train(model, dis_x, dis_y, dis_path, net, epoch):\n    if not os.path.exists('tmp'):\n        os.mkdir('tmp')\n    # show prediction\n    pred = np.squeeze(model.predict(np.expand_dims(dis_x, axis=0)))\n    _, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n    ax_x_ori.imshow(cv2.cvtColor(cv2.imread(dis_path), cv2.COLOR_BGR2RGB))\n    ax_x_ori.set_title('Original Image')\n    ax_y.imshow(np.squeeze(dis_y), cmap=plt.cm.jet)\n    ax_y.set_title('Ground_truth: ' + str(np.sum(dis_y)))\n    ax_pred.imshow(pred, cmap=plt.cm.jet)\n    ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n    plt.savefig('tmp/{}_{}-epoch.png'.format(net, epoch))\n    return None\n\n\ndef eval_loss(model, x, y, quality=False):\n    preds, DM, GT = [], [], []\n    losses_SFN, losses_MAE, losses_MAPE, losses_RMSE = [], [], [], []\n    for idx_pd in range(x.shape[0]):\n        pred = model.predict(np.array([x[idx_pd]]))\n        preds.append(np.squeeze(pred))\n        DM.append(np.squeeze(np.array([y[idx_pd]])))\n        GT.append(round(np.sum(np.array([y[idx_pd]]))))    # To make sure the GT is an integral value\n    for idx_pd in range(len(preds)):\n        losses_SFN.append(np.mean(np.square(preds[idx_pd] - DM[idx_pd])))     # mean of Frobenius norm\n        losses_MAE.append(np.abs(np.sum(preds[idx_pd]) - GT[idx_pd]))\n        losses_MAPE.append(np.abs(np.sum(preds[idx_pd]) - GT[idx_pd]) / GT[idx_pd])\n        losses_RMSE.append(np.square(np.sum(preds[idx_pd]) - GT[idx_pd]))\n\n    loss_SFN = np.sum(losses_SFN)\n    loss_MAE = np.mean(losses_MAE)\n    loss_MAPE = np.mean(losses_MAPE)\n    loss_RMSE = np.sqrt(np.mean(losses_RMSE))\n    if quality:\n\n        psnr, ssim = [], []\n        for idx_pd in range(len(preds)):\n            data_range = max([np.max(preds[idx_pd]), np.max(DM[idx_pd])]) - min([np.min(preds[idx_pd]), np.min(DM[idx_pd])])\n            psnr_ = compare_psnr(preds[idx_pd], DM[idx_pd], data_range=data_range)\n            ssim_ = compare_ssim(preds[idx_pd], DM[idx_pd], data_range=data_range)\n            psnr.append(psnr_)\n            ssim.append(ssim_)\n        return loss_MAE, loss_RMSE, loss_SFN, loss_MAPE, np.mean(psnr), np.mean(ssim)\n    print(\"MAE=\"+str(loss_MAE))\n    print(\"RMSE=\"+str(loss_RMSE))\n    return loss_MAE, loss_RMSE, loss_SFN, loss_MAPE\n\nnet = 'Crowd'\ndataset = \"B\"","metadata":{"id":"TP7vUpgc5mrF","execution":{"iopub.status.busy":"2021-12-13T08:23:33.742889Z","iopub.execute_input":"2021-12-13T08:23:33.743143Z","iopub.status.idle":"2021-12-13T08:23:34.049321Z","shell.execute_reply.started":"2021-12-13T08:23:33.743115Z","shell.execute_reply":"2021-12-13T08:23:34.048488Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"id":"AqwOXM3u7GZR","outputId":"cdcad40b-2348-4b8e-bc3b-c0f5987f35d3","execution":{"iopub.status.busy":"2021-12-13T06:48:51.815518Z","iopub.execute_input":"2021-12-13T06:48:51.815764Z","iopub.status.idle":"2021-12-13T06:48:51.823318Z","shell.execute_reply.started":"2021-12-13T06:48:51.815731Z","shell.execute_reply":"2021-12-13T06:48:51.822653Z"},"editable":false,"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"(train_img_paths,train_dm_paths)=gen_paths_img_dm('/content/drive/MyDrive/ShanghaiTech/part_B/train_data')\ntrain_x, train_y = gen_var_from_paths(train_img_paths[:], unit_len=None), gen_var_from_paths(train_dm_paths[:], stride=8, unit_len=None)\nprint('Train data size:', train_x.shape[0], train_y.shape[0], len(train_img_paths))\n","metadata":{"id":"cxp2OInxL7RG","outputId":"2cf64c40-fdaf-4c86-8662-c867346c38df","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x.shape\ntrain_y.shape\nimport gc\ngc.collect()\n(test_img_paths,test_dm_paths)=gen_paths_img_dm('/content/drive/MyDrive/ShanghaiTech/part_B')\ntest_x, test_y = gen_var_from_paths(test_img_paths[:], unit_len=None), gen_var_from_paths(test_dm_paths[:], stride=8, unit_len=None)\ntest_x = norm_by_imagenet(test_x)  # Normalization on raw images in test set, those of training set are in image_preprocessing below.\nprint('Test data size:', test_x.shape[0], test_y.shape[0], len(test_img_paths))","metadata":{"id":"JceWn-xHMVDn","outputId":"f3547a99-41d3-40c2-f6eb-a3340b846894","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntrain_x=np.load('../input/federatedlearning/TrainSTBXIP.npy')\ntrain_y=np.load('../input/federatedlearning/TrainSTBYIP.npy')\ntest_x=np.load('../input/federatedlearning/TestSTBx.npy')\ntest_y=np.load('../input/federatedlearning/TestSTBy.npy')","metadata":{"id":"WOaU-5In5xBx","execution":{"iopub.status.busy":"2021-12-13T06:47:37.662877Z","iopub.execute_input":"2021-12-13T06:47:37.663151Z","iopub.status.idle":"2021-12-13T06:48:51.813979Z","shell.execute_reply.started":"2021-12-13T06:47:37.663122Z","shell.execute_reply":"2021-12-13T06:48:51.813129Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"length = len(test_x)\nmiddle_index = 100\ntestx = test_x[:middle_index]\nlength = len(test_y)\nmiddle_index = 100\ntesty = test_y[:middle_index]","metadata":{"id":"G0_lOuCW8hR9","execution":{"iopub.status.busy":"2021-12-13T06:48:51.825001Z","iopub.execute_input":"2021-12-13T06:48:51.825548Z","iopub.status.idle":"2021-12-13T06:48:51.832069Z","shell.execute_reply.started":"2021-12-13T06:48:51.825512Z","shell.execute_reply":"2021-12-13T06:48:51.831249Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"length = len(train_x)\nmiddle_index = length//2\n#Floor division rounds down\n\n\nclient1x = train_x[:middle_index]\n\nclient2x = train_x[middle_index:]","metadata":{"id":"hi3N3AYM56Ms","execution":{"iopub.status.busy":"2021-12-13T06:48:51.834410Z","iopub.execute_input":"2021-12-13T06:48:51.834719Z","iopub.status.idle":"2021-12-13T06:48:51.845225Z","shell.execute_reply.started":"2021-12-13T06:48:51.834684Z","shell.execute_reply":"2021-12-13T06:48:51.844547Z"},"editable":false,"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"length = len(train_y)\nmiddle_index = length//2\n\nclient1y = train_y[:middle_index]\n\nclient2y = train_y[middle_index:]","metadata":{"id":"tg-GltU85muE","execution":{"iopub.status.busy":"2021-12-13T06:48:51.846469Z","iopub.execute_input":"2021-12-13T06:48:51.846727Z","iopub.status.idle":"2021-12-13T06:48:51.854666Z","shell.execute_reply.started":"2021-12-13T06:48:51.846694Z","shell.execute_reply":"2021-12-13T06:48:51.853919Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, Conv2D, Input, MaxPooling2D, concatenate, add, UpSampling2D\nfrom keras.models import Model\nfrom keras.initializers import RandomNormal\n\n\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers.core import Dense, Activation, Dropout, Flatten\nfrom keras.layers.recurrent import SimpleRNN, LSTM, GRU\nfrom keras.layers.wrappers import TimeDistributed\n\ndef stbflmodel(input_shape=(None, None, 3)):\n\n    input_flow = Input(shape=input_shape)\n    dilated_conv_kernel_initializer = RandomNormal(stddev=0.01)\n\n    # front-end\n    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(input_flow)\n    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    \n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n\n    # back-end\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', dilation_rate=2, activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n\n    output_flow = Conv2D(1, 1, strides=(1, 1), padding='same', activation='relu', kernel_initializer=dilated_conv_kernel_initializer)(x)\n    model = Model(inputs=input_flow, outputs=output_flow)\n\n    front_end = VGG16(weights='imagenet', include_top=False)\n\n    weights_front_end = []\n    for layer in front_end.layers:\n        if 'conv' in layer.name:\n            weights_front_end.append(layer.get_weights())\n    counter_conv = 0\n    for i in range(len(front_end.layers)):\n        if counter_conv >= 10:\n            break\n        if 'conv' in model.layers[i].name:\n            model.layers[i].set_weights(weights_front_end[counter_conv])\n            counter_conv += 1\n\n    return model\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nLOSS = 'MSE'\noptimizer = Adam(learning_rate=1e-5)\nmodel = stbflmodel(input_shape=(None,None, 3))\nLOSS = 'MSE'\nmetrics = ['accuracy']\n#optimizer = Adam(learning_rate=1e-5)\n#model = stbflmodel(input_shape=(None,None, 3))\n\n#model.compile(optimizer=optimizer, loss='MSE')\nmodel.compile(optimizer=optimizer, loss='MSE',metrics=metrics)\nmodel.summary()\nif not os.path.exists('models'):\n    os.makedirs('models')\nplot_model(model, 'models/{}.png'.format(net))\nwith open('./models/{}.json'.format(net), 'w') as fout:\n    fout.write(model.to_json())\n","metadata":{"id":"mrd7_YuqEtBW","outputId":"bec9672e-c10c-49aa-a190-af7606832142","execution":{"iopub.status.busy":"2021-12-13T06:48:51.857595Z","iopub.execute_input":"2021-12-13T06:48:51.857783Z","iopub.status.idle":"2021-12-13T06:48:57.401054Z","shell.execute_reply.started":"2021-12-13T06:48:51.857753Z","shell.execute_reply":"2021-12-13T06:48:57.400222Z"},"editable":false,"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2021-12-13 06:48:52.270436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:52.362275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:52.362964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:52.364094: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-12-13 06:48:52.364416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:52.365104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:52.365727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:54.199394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:54.200202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:54.200834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-13 06:48:54.201959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\n58900480/58889256 [==============================] - 1s 0us/step\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, None, None, 3)]   0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, None, None, 64)    1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, None, None, 64)    36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, None, None, 64)    0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, None, None, 128)   73856     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, None, None, 128)   147584    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, None, None, 128)   0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, None, None, 256)   295168    \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, None, None, 256)   590080    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, None, None, 256)   590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, None, None, 256)   0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, None, None, 512)   1180160   \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, None, None, 512)   2359808   \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, None, None, 512)   2359808   \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, None, None, 512)   2359808   \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, None, None, 512)   2359808   \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, None, None, 512)   2359808   \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, None, None, 256)   1179904   \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, None, None, 128)   295040    \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, None, None, 64)    73792     \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, None, None, 1)     65        \n=================================================================\nTotal params: 16,263,489\nTrainable params: 16,263,489\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def weight_scalling_factor():\n    \n    global_count = 400\n    \n    local_count = 200\n    \n    return local_count/global_count\n\n\ndef scale_model_weights(weight, scalar):\n    '''function for scaling a models weights'''\n    weight_final = []\n    steps = len(weight)\n    for i in range(steps):\n        weight_final.append(scalar * weight[i])\n    return weight_final\n\n\n\ndef sum_scaled_weights(scaled_weight_list):\n    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n    avg_grad = list()\n    #get the average grad accross all client gradients\n    for grad_list_tuple in zip(*scaled_weight_list):\n        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n        avg_grad.append(layer_mean)\n        \n    return avg_grad\n\n\ndef test_model(X_test, Y_test,  model, comm_round):\n    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n    #logits = model.predict(X_test, batch_size=100)\n    logits = model.predict(X_test)\n    loss = cce(Y_test, logits)\n    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n    return acc, loss","metadata":{"id":"ouXwfbN45mwz","execution":{"iopub.status.busy":"2021-12-13T06:48:57.402597Z","iopub.execute_input":"2021-12-13T06:48:57.402848Z","iopub.status.idle":"2021-12-13T06:48:57.415828Z","shell.execute_reply.started":"2021-12-13T06:48:57.402811Z","shell.execute_reply":"2021-12-13T06:48:57.414964Z"},"editable":false,"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\n#train_y.shape","metadata":{"id":"7Lpp40vTBWsT","outputId":"a07c228e-6826-4123-fba6-79d1dc20372c","execution":{"iopub.status.busy":"2021-12-13T06:48:57.417319Z","iopub.execute_input":"2021-12-13T06:48:57.417665Z","iopub.status.idle":"2021-12-13T06:48:57.774635Z","shell.execute_reply.started":"2021-12-13T06:48:57.417628Z","shell.execute_reply":"2021-12-13T06:48:57.773961Z"},"editable":false,"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"7193"},"metadata":{}}]},{"cell_type":"code","source":"\n\nLOSS = 'MSE'\nmetrics = ['accuracy']\noptimizer = Adam(learning_rate=1e-5)\nglobal_model = stbflmodel(input_shape=(None,None, 3))\n\nglobal_model.compile(optimizer=optimizer, loss='MSE',metrics=metrics)\n#new_model = tf.keras.models.load_model('my_model.h5')","metadata":{"id":"P9OUiVPp5mz7","execution":{"iopub.status.busy":"2021-12-13T06:48:57.775973Z","iopub.execute_input":"2021-12-13T06:48:57.776248Z","iopub.status.idle":"2021-12-13T06:48:58.424656Z","shell.execute_reply.started":"2021-12-13T06:48:57.776195Z","shell.execute_reply":"2021-12-13T06:48:58.423882Z"},"editable":false,"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n#train_x=np.load('/content/drive/MyDrive/TrainSTBXIP.npy')\n#train_y=np.load('/content/drive/MyDrive/TrainSTBYIP.npy')\ntestx=np.load('/content/drive/MyDrive/TestSTBx.npy')\ntesty=np.load('/content/drive/MyDrive/TestSTBy.npy')\ngl= eval_loss(global_model, testx, testy, quality=False)","metadata":{"id":"sqbUv558sWTv","outputId":"37ddac32-b522-4c0c-c10d-36ff4afed820","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"n6Qt64LQ0n7I","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntestx=np.load('/content/drive/MyDrive/TestSTBx.npy')\ntesty=np.load('/content/drive/MyDrive/TestSTBy.npy')","metadata":{"id":"FRfb0IW-23Cw","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(15):\n     print(\"comm_round\"+str(i))\n     global_weights = global_model.get_weights()\n     scaled_local_weight_list = list()\n\n     print(\"enter client1\")\n        \n     LOSS = 'MSE'\n     metrics = ['accuracy']\n     optimizer = Adam(learning_rate=1e-5)\n     local_model = stbflmodel(input_shape=(None,None, 3))\n\n     local_model.compile(optimizer=optimizer, loss='MSE')\n        \n     local_model.set_weights(global_weights)\n     for ep in range(1):\n        for idx_train in range(0, 200, 16):\n        \n           x, y = client1x[idx_train:idx_train+16], client1y[idx_train:idx_train+16]\n       \n           local_model.fit(x, y, batch_size=1, verbose=1)\n        \n       \n        \n     scaling_factor = weight_scalling_factor()\n     scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n     scaled_local_weight_list.append(scaled_weights)        \n     print(\"enter client2\")\n        \n     LOSS = 'MSE'\n     metrics = ['accuracy']\n     optimizer = Adam(learning_rate=1e-5)\n     local_model2 = stbflmodel(input_shape=(None,None, 3))\n\n     local_model2.compile(optimizer=optimizer, loss='MSE')\n        #set local model weight to the weight of the global model\n     local_model2.set_weights(global_weights)\n     for ep in range(1):\n        for idx_train in range(0, 200, 16):\n        \n           x, y = client2x[idx_train:idx_train+16], client2y[idx_train:idx_train+16]\n    \n           local_model2.fit(x, y, batch_size=1, verbose=1)\n        \n     scaling_factor = weight_scalling_factor()\n     scaled_weights = scale_model_weights(local_model2.get_weights(), scaling_factor)\n     scaled_local_weight_list.append(scaled_weights)  \n     average_weights = sum_scaled_weights(scaled_local_weight_list)\n    \n    #update global model \n     global_model.set_weights(average_weights)\n     print(\"global test\")\n     \n     gl= eval_loss(global_model, test_x, test_y, quality=False)\n","metadata":{"id":"_QJOhnPGz8lj","outputId":"a0ae8206-4711-4f58-85c5-52a58c1e0655","execution":{"iopub.status.busy":"2021-12-13T06:49:48.873268Z","iopub.execute_input":"2021-12-13T06:49:48.873527Z","iopub.status.idle":"2021-12-13T07:25:29.457426Z","shell.execute_reply.started":"2021-12-13T06:49:48.873498Z","shell.execute_reply":"2021-12-13T07:25:29.456622Z"},"editable":false,"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"comm_round0\nenter client1\n16/16 [==============================] - 4s 170ms/step - loss: 0.0026\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 172ms/step - loss: 0.0039\n16/16 [==============================] - 3s 169ms/step - loss: 0.0025\n16/16 [==============================] - 3s 169ms/step - loss: 0.0028\n16/16 [==============================] - 3s 170ms/step - loss: 0.0064\n16/16 [==============================] - 3s 168ms/step - loss: 0.0037\n16/16 [==============================] - 3s 169ms/step - loss: 0.0035\n16/16 [==============================] - 3s 169ms/step - loss: 0.0021\n16/16 [==============================] - 3s 170ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 8.7214e-04\n8/8 [==============================] - 1s 169ms/step - loss: 7.0726e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0023\n16/16 [==============================] - 3s 170ms/step - loss: 0.0025\n16/16 [==============================] - 3s 169ms/step - loss: 0.0021\n16/16 [==============================] - 3s 170ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 5.7722e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 170ms/step - loss: 0.0018\n16/16 [==============================] - 3s 170ms/step - loss: 0.0036\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 8.1666e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0051\nglobal test\nMAE=53.932267394246935\nRMSE=77.08936030857596\ncomm_round1\nenter client1\n16/16 [==============================] - 4s 171ms/step - loss: 0.0020\n16/16 [==============================] - 3s 172ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 170ms/step - loss: 0.0029\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0023\n16/16 [==============================] - 3s 169ms/step - loss: 0.0048\n16/16 [==============================] - 3s 168ms/step - loss: 0.0033\n16/16 [==============================] - 3s 169ms/step - loss: 0.0027\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 171ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 7.0220e-04\n8/8 [==============================] - 1s 169ms/step - loss: 5.7850e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 170ms/step - loss: 0.0016\n16/16 [==============================] - 3s 171ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 5.6480e-04\n16/16 [==============================] - 3s 170ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 172ms/step - loss: 0.0033\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 5.5790e-04\n8/8 [==============================] - 1s 171ms/step - loss: 0.0035\nglobal test\nMAE=26.217662455160408\nRMSE=35.74969600777497\ncomm_round2\nenter client1\n16/16 [==============================] - 4s 171ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0026\n16/16 [==============================] - 3s 168ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0022\n16/16 [==============================] - 3s 171ms/step - loss: 0.0040\n16/16 [==============================] - 3s 169ms/step - loss: 0.0030\n16/16 [==============================] - 3s 168ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 6.7144e-04\n8/8 [==============================] - 1s 170ms/step - loss: 5.4529e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 170ms/step - loss: 0.0018\n16/16 [==============================] - 3s 170ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 170ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 5.2925e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0023\n16/16 [==============================] - 3s 174ms/step - loss: 0.0016\n16/16 [==============================] - 3s 168ms/step - loss: 4.9986e-04\n8/8 [==============================] - 1s 170ms/step - loss: 0.0031\nglobal test\nMAE=21.656764451461502\nRMSE=31.384419068344684\ncomm_round3\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 173ms/step - loss: 0.0023\n16/16 [==============================] - 3s 170ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 170ms/step - loss: 0.0044\n16/16 [==============================] - 3s 169ms/step - loss: 0.0028\n16/16 [==============================] - 3s 169ms/step - loss: 0.0028\n16/16 [==============================] - 3s 169ms/step - loss: 0.0022\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 6.0170e-04\n8/8 [==============================] - 1s 172ms/step - loss: 5.1128e-04\nenter client2\n16/16 [==============================] - 4s 168ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 0.0013\n16/16 [==============================] - 3s 171ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 4.5950e-04\n16/16 [==============================] - 3s 172ms/step - loss: 9.7299e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0021\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 4.7797e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0029\nglobal test\nMAE=21.16073151932487\nRMSE=30.209010861292086\ncomm_round4\nenter client1\n16/16 [==============================] - 4s 171ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 170ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0036\n16/16 [==============================] - 3s 171ms/step - loss: 0.0027\n16/16 [==============================] - 3s 170ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 170ms/step - loss: 5.9670e-04\n8/8 [==============================] - 1s 169ms/step - loss: 4.9067e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 171ms/step - loss: 0.0014\n16/16 [==============================] - 3s 171ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 4.1562e-04\n16/16 [==============================] - 3s 169ms/step - loss: 9.2727e-04\n16/16 [==============================] - 3s 170ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 4.8957e-04\n8/8 [==============================] - 1s 170ms/step - loss: 0.0028\nglobal test\nMAE=29.56457550616204\nRMSE=38.76656024070488\ncomm_round5\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 170ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 170ms/step - loss: 0.0020\n16/16 [==============================] - 3s 170ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 0.0033\n16/16 [==============================] - 3s 169ms/step - loss: 0.0029\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 5.4966e-04\n8/8 [==============================] - 1s 169ms/step - loss: 4.8758e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 171ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 5.2661e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0011\n16/16 [==============================] - 3s 170ms/step - loss: 0.0012\n16/16 [==============================] - 3s 171ms/step - loss: 0.0023\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 170ms/step - loss: 4.8756e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0027\nglobal test\nMAE=16.37455783011038\nRMSE=23.509073285650672\ncomm_round6\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 170ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 171ms/step - loss: 0.0022\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0032\n16/16 [==============================] - 3s 169ms/step - loss: 0.0024\n16/16 [==============================] - 3s 168ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 168ms/step - loss: 5.5340e-04\n8/8 [==============================] - 1s 169ms/step - loss: 4.9407e-04\nenter client2\n16/16 [==============================] - 4s 168ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 9.9509e-04\n16/16 [==============================] - 3s 169ms/step - loss: 4.2536e-04\n16/16 [==============================] - 3s 168ms/step - loss: 8.9823e-04\n16/16 [==============================] - 3s 171ms/step - loss: 9.4986e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 4.4942e-04\n8/8 [==============================] - 1s 168ms/step - loss: 0.0026\nglobal test\nMAE=24.86714624981337\nRMSE=31.442500746815252\ncomm_round7\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 171ms/step - loss: 9.4657e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0011\n16/16 [==============================] - 3s 170ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 168ms/step - loss: 0.0018\n16/16 [==============================] - 3s 168ms/step - loss: 0.0045\n16/16 [==============================] - 3s 169ms/step - loss: 0.0027\n16/16 [==============================] - 3s 169ms/step - loss: 0.0038\n16/16 [==============================] - 3s 169ms/step - loss: 0.0029\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 8.0381e-04\n8/8 [==============================] - 1s 171ms/step - loss: 7.1968e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 0.0015\n16/16 [==============================] - 3s 170ms/step - loss: 9.8517e-04\n16/16 [==============================] - 3s 169ms/step - loss: 4.0872e-04\n16/16 [==============================] - 3s 169ms/step - loss: 8.6854e-04\n16/16 [==============================] - 3s 169ms/step - loss: 8.5936e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 171ms/step - loss: 4.1767e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0026\nglobal test\nMAE=29.330646877047382\nRMSE=40.26900754721945\ncomm_round8\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 168ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0030\n16/16 [==============================] - 3s 168ms/step - loss: 0.0026\n16/16 [==============================] - 3s 170ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 168ms/step - loss: 6.3467e-04\n8/8 [==============================] - 1s 176ms/step - loss: 5.8517e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 9.5497e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 170ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 171ms/step - loss: 4.1033e-04 0s - loss: 2.69\n16/16 [==============================] - 3s 168ms/step - loss: 8.3958e-04\n16/16 [==============================] - 3s 169ms/step - loss: 8.3961e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 4.5650e-04\n8/8 [==============================] - 1s 168ms/step - loss: 0.0028\nglobal test\nMAE=26.800068945824346\nRMSE=35.43108935020355\ncomm_round9\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 9.1211e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 168ms/step - loss: 0.0014\n16/16 [==============================] - 3s 168ms/step - loss: 0.0014\n16/16 [==============================] - 3s 171ms/step - loss: 0.0029\n16/16 [==============================] - 3s 169ms/step - loss: 0.0023\n16/16 [==============================] - 3s 169ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 170ms/step - loss: 4.9098e-04\n8/8 [==============================] - 1s 169ms/step - loss: 4.6269e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 171ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 8.5364e-04\n16/16 [==============================] - 3s 169ms/step - loss: 5.4608e-04\n16/16 [==============================] - 3s 169ms/step - loss: 9.5427e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0017\n16/16 [==============================] - 3s 170ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 4.1768e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0025\nglobal test\nMAE=20.632381858704964\nRMSE=29.270584727879616\ncomm_round10\nenter client1\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0029\n16/16 [==============================] - 3s 168ms/step - loss: 0.0022\n16/16 [==============================] - 3s 169ms/step - loss: 0.0022\n16/16 [==============================] - 3s 169ms/step - loss: 0.0022\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 172ms/step - loss: 5.4210e-04\n8/8 [==============================] - 1s 169ms/step - loss: 5.3994e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 170ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 171ms/step - loss: 8.4445e-04\n16/16 [==============================] - 3s 169ms/step - loss: 3.6101e-04\n16/16 [==============================] - 3s 170ms/step - loss: 8.0534e-04\n16/16 [==============================] - 3s 170ms/step - loss: 8.0279e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - 3s 168ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 4.4015e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0026\nglobal test\nMAE=24.851350221452833\nRMSE=34.08709013758824\ncomm_round11\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 9.2407e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 170ms/step - loss: 0.0018\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 170ms/step - loss: 0.0026\n16/16 [==============================] - 3s 168ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0025\n16/16 [==============================] - 3s 168ms/step - loss: 0.0018\n16/16 [==============================] - 3s 168ms/step - loss: 0.0010\n16/16 [==============================] - 3s 169ms/step - loss: 4.9736e-04\n8/8 [==============================] - 1s 168ms/step - loss: 4.6587e-04\nenter client2\n16/16 [==============================] - 4s 168ms/step - loss: 0.0012\n16/16 [==============================] - 3s 168ms/step - loss: 0.0015\n16/16 [==============================] - 3s 168ms/step - loss: 0.0015\n16/16 [==============================] - 3s 170ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 7.9998e-04\n16/16 [==============================] - 3s 172ms/step - loss: 3.4280e-04\n16/16 [==============================] - 3s 169ms/step - loss: 7.7626e-04\n16/16 [==============================] - 3s 169ms/step - loss: 7.2703e-04\n16/16 [==============================] - 3s 174ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 170ms/step - loss: 3.9564e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0025\nglobal test\nMAE=17.12755084867719\nRMSE=25.42364450039757\ncomm_round12\nenter client1\n16/16 [==============================] - 4s 168ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 9.6111e-04\n16/16 [==============================] - 3s 174ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0017\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 0.0026\n16/16 [==============================] - 3s 168ms/step - loss: 0.0025\n16/16 [==============================] - 3s 170ms/step - loss: 0.0023\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 173ms/step - loss: 4.8996e-04\n8/8 [==============================] - 1s 168ms/step - loss: 4.4730e-04\nenter client2\n16/16 [==============================] - 3s 168ms/step - loss: 9.6840e-04\n16/16 [==============================] - 3s 169ms/step - loss: 8.9985e-04\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 169ms/step - loss: 0.0016\n16/16 [==============================] - ETA: 0s - loss: 0.0012MAE=13.728879678098462\nRMSE=20.31825705316079\ncomm_round13\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 173ms/step - loss: 8.6781e-04\n16/16 [==============================] - 3s 169ms/step - loss: 9.7408e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0018\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 0.0025\n16/16 [==============================] - 3s 169ms/step - loss: 0.0020\n16/16 [==============================] - 3s 169ms/step - loss: 0.0018\n16/16 [==============================] - 3s 169ms/step - loss: 0.0015\n16/16 [==============================] - 3s 170ms/step - loss: 0.0017\n16/16 [==============================] - 3s 168ms/step - loss: 5.7720e-04\n8/8 [==============================] - 1s 169ms/step - loss: 5.4113e-04\nenter client2\n16/16 [==============================] - 4s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 0.0014\n16/16 [==============================] - 3s 169ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0011\n16/16 [==============================] - 3s 168ms/step - loss: 0.0013\n16/16 [==============================] - 3s 168ms/step - loss: 3.7249e-04\n16/16 [==============================] - 3s 168ms/step - loss: 7.5632e-04\n16/16 [==============================] - 3s 170ms/step - loss: 8.0998e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0023\n16/16 [==============================] - 3s 168ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 4.5776e-04\n8/8 [==============================] - 1s 169ms/step - loss: 0.0025\nglobal test\nMAE=19.12166855305056\nRMSE=33.746871617685635\ncomm_round14\nenter client1\n16/16 [==============================] - 4s 169ms/step - loss: 0.0013\n16/16 [==============================] - 3s 169ms/step - loss: 8.4725e-04\n16/16 [==============================] - 3s 168ms/step - loss: 9.8059e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0018\n16/16 [==============================] - 3s 170ms/step - loss: 0.0012\n16/16 [==============================] - 3s 169ms/step - loss: 0.0012\n16/16 [==============================] - 3s 175ms/step - loss: 0.0024\n16/16 [==============================] - 3s 169ms/step - loss: 0.0019\n16/16 [==============================] - 3s 168ms/step - loss: 0.0016\n16/16 [==============================] - 3s 169ms/step - loss: 0.0010\n16/16 [==============================] - 3s 168ms/step - loss: 9.5726e-04\n16/16 [==============================] - 3s 173ms/step - loss: 4.5966e-04\n8/8 [==============================] - 1s 169ms/step - loss: 4.3585e-04\nenter client2\n16/16 [==============================] - 3s 168ms/step - loss: 9.8723e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0010\n16/16 [==============================] - 3s 171ms/step - loss: 0.0015\n16/16 [==============================] - 3s 168ms/step - loss: 0.0011\n16/16 [==============================] - 3s 169ms/step - loss: 9.4469e-04\n16/16 [==============================] - 3s 169ms/step - loss: 7.6968e-04\n16/16 [==============================] - 3s 168ms/step - loss: 3.2717e-04\n16/16 [==============================] - 3s 171ms/step - loss: 7.6864e-04\n16/16 [==============================] - 3s 169ms/step - loss: 7.3047e-04\n16/16 [==============================] - 3s 168ms/step - loss: 0.0020\n16/16 [==============================] - 3s 172ms/step - loss: 0.0014\n16/16 [==============================] - 3s 168ms/step - loss: 4.5369e-04\n8/8 [==============================] - 1s 168ms/step - loss: 0.0025\nglobal test\nMAE=14.742389214189746\nRMSE=22.422421359409174\n","output_type":"stream"}]},{"cell_type":"code","source":"        print(\"comm_round1\")\n        global_weights = global_model.get_weights()\n        scaled_local_weight_list = list()\n        print(\"enter client1\")\n        #smlp_local = SimpleMLP()\n        #local_model = smlp_local.build(784, 10)\n        #local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n        LOSS = 'MSE'\n        metrics = ['accuracy']\n        optimizer = Adam(learning_rate=1e-5)\n        local_model = stbflmodel(input_shape=(None,None, 3))\n\n        local_model.compile(optimizer=optimizer, loss='MSE',metrics=metrics)\n        #set local model weight to the weight of the global model\n        local_model.set_weights(global_weights)\n        local_model.fit(client2x,client2y, batch_size=16,epochs=1, verbose=1)\n        \n        #scale the model weights and add to list\n        scaling_factor = weight_scalling_factor()\n        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n        scaled_local_weight_list.append(scaled_weights)\n        ","metadata":{"id":"NIRpE-LRBjvD","outputId":"5d097fcf-8063-4f53-d9e5-740d9551fef0","editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"kz4ZDlvPEliw","outputId":"cdbee1bc-6641-4f9e-ce1f-68d749773ebf","execution":{"iopub.status.busy":"2021-12-13T07:25:37.312785Z","iopub.execute_input":"2021-12-13T07:25:37.313195Z","iopub.status.idle":"2021-12-13T07:25:37.474943Z","shell.execute_reply.started":"2021-12-13T07:25:37.313160Z","shell.execute_reply":"2021-12-13T07:25:37.474219Z"},"editable":false,"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\ntestx=np.load('../input/federatedlearning/TestSTBx.npy')\ntesty=np.load('../input/federatedlearning/TestSTBy.npy')\nglobalmodel = tf.keras.models.load_model('../input/weights/fedlmodel.h5')\ngl= eval_loss(globalmodel, testx, testy, quality=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T08:24:39.744007Z","iopub.execute_input":"2021-12-13T08:24:39.744266Z","iopub.status.idle":"2021-12-13T08:25:17.522870Z","shell.execute_reply.started":"2021-12-13T08:24:39.744236Z","shell.execute_reply":"2021-12-13T08:25:17.522106Z"},"editable":false,"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"MAE=31.903633799733996\nRMSE=38.75989848438039\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n                          ","metadata":{"id":"ezMMDlghElfc","outputId":"49eb1cca-b72d-48fb-cf42-f457af8de768","execution":{"iopub.status.busy":"2021-12-13T08:24:36.275417Z","iopub.execute_input":"2021-12-13T08:24:36.275997Z","iopub.status.idle":"2021-12-13T08:24:36.281204Z","shell.execute_reply.started":"2021-12-13T08:24:36.275949Z","shell.execute_reply":"2021-12-13T08:24:36.280313Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#gl= eval_loss(globalmodel, testx, testy, quality=False)","metadata":{"id":"xcrph0LlElVU","execution":{"iopub.status.busy":"2021-12-13T00:28:15.682032Z","iopub.execute_input":"2021-12-13T00:28:15.68311Z","iopub.status.idle":"2021-12-13T00:28:47.829665Z","shell.execute_reply.started":"2021-12-13T00:28:15.683067Z","shell.execute_reply":"2021-12-13T00:28:47.828882Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}